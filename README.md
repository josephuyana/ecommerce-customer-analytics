# E-commerce Customer Analytics

Analyze real UK-based online retail transactions to deliver actionable insights on customer behavior and sales performance.

## Table of Contents
1. [Goals](#goals)  
2. [Installation](#installation)  
3. [Dataset](#dataset)  
4. [Project Structure](#project-structure)  
5. [Data Cleaning](#data-cleaning)  
6. [RFM Segmentation](#rfm-segmentation)  
7. [Key Visualizations](#key-visualizations)  
8. [Interactive Dashboard](#interactive-dashboard)  
9. [Usage](#usage)  
10. [Requirements](#requirements)  
11. [Contributing](#contributing)  
12. [License & Contact](#license--contact)

---

## Goals

- Analyze sales patterns over time and across regions.  
- Segment customers with RFM (Recency, Frequency, Monetary) model.  
- Create static and interactive visualizations of business KPIs.  
- Build a Streamlit app for dynamic data exploration.

---

## Installation

```bash
git clone https://github.com/your-username/ecommerce-customer-analytics.git
cd ecommerce-customer-analytics
python3 -m venv .venv
source .venv/bin/activate          # Windows: .venv\Scripts\Activate.ps1
pip install -r requirements.txt
```

## Dataset

- **Source**: UCI Machine Learning Repository â€“ Online Retail Dataset  
- **Link**: [https://archive.ics.uci.edu/ml/datasets/Online+Retail](https://archive.ics.uci.edu/ml/datasets/Online+Retail)  
- **Description**:  
  This dataset contains all transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered online retailer.  
- **Records**: ~541,909 transactions  
- **Fields** include:
  - `InvoiceNo`: Invoice number (cancellations marked with "C")  
  - `StockCode`: Product code  
  - `Description`: Product name  
  - `Quantity`: Number of items per invoice  
  - `InvoiceDate`: Timestamp of transaction  
  - `UnitPrice`: Product price per unit  
  - `CustomerID`: Unique customer identifier  
  - `Country`: Customerâ€™s country  

## Project Structure

```
    â”œâ”€â”€ data/
    â”‚ â”œâ”€â”€ Online Retail.xlsx # Raw dataset
    â”‚ â””â”€â”€ cleaned_retail.csv # After cleaning
    â”œâ”€â”€ notebooks/
    â”‚ â”œâ”€â”€ 01_cleaning.ipynb # Data cleaning steps
    â”‚ â”œâ”€â”€ 02_rfm.ipynb # RFM calculation & scoring
    â”‚ â””â”€â”€ 04_visualizations.ipynb # Static visualizations
    â”œâ”€â”€ dashboards/
    â”‚ â””â”€â”€ app.py # Streamlit interactive dashboard
    â”œâ”€â”€ sql/
    â”‚ â””â”€â”€ analysis.sql # Optional SQL queries
    â”œâ”€â”€ requirements.txt # Python dependencies
    â””â”€â”€ README.md # Project overview
```

This structure separates data processing, analysis, and interface layers to ensure modularity and clarity.


## Data Cleaning

The dataset required multiple preprocessing steps to ensure reliability for analysis:

- âœ… **Removed duplicate records** using `.drop_duplicates()`.  
- âœ… **Filtered cancelled transactions**: invoices starting with `"C"` were excluded.  
- âœ… **Excluded missing customer IDs** to focus only on identified buyers.  
- âœ… **Saved cleaned dataset** as `data/cleaned_retail.csv` for reuse in analysis and dashboard development.

All cleaning steps are fully documented and reproducible in `notebooks/01_cleaning.ipynb`.

## RFM Segmentation

We used the RFM (Recency, Frequency, Monetary) model to segment customers based on purchasing behavior.

### Steps:

1. **Reference Date**: Set to one day after the last invoice date in the dataset.
2. **Recency**: Number of days since the customer's last purchase.
3. **Frequency**: Number of unique purchase events (`InvoiceNo`) per customer.
4. **Monetary Value**: Total revenue generated by each customer (`UnitPrice Ã— Quantity`).

### Scoring:

- Each metric was converted into a **percent-rank** and then mapped to a **quintile score** (1 to 5).
- Recency was inverted (lower = better), so higher scores represent better recency.
- Final segments were encoded as a 3-digit string (e.g., `'555'` = most recent, most frequent, highest spenders).
- A total `RFM_Score` (sum of R, F, M) was also calculated to rank customers from 3 to 15.

â¡ï¸ Output: All results are saved to `data/rfm_segments.csv`.  
â¡ï¸ Code: See full implementation in `notebooks/02_rfm.ipynb`.

## Key Visualizations

The following charts were created to extract insights from the RFM segmentation:

- ğŸ“Š **Top 10 RFM Segments + Other**: highlights the most populated customer segments and aggregates the rest into "Other" for clarity.
- ğŸ“Š **RFM Score Distribution**: shows how customers are distributed by total RFM score (from 3 to 15).
- ğŸ”¥ **Recency vs. Frequency Heatmap**: reveals average spend patterns by recency and frequency combinations.
- ğŸ’° **Top 5 Segments by Revenue Share**: identifies customer groups that generate the majority of revenue.
- ğŸ“¦ **Spend Distribution Boxplot**: visualizes variability in spending within the top 5 high-value segments.

These visualizations are included in `notebooks/04_visualizations.ipynb` and were generated using Matplotlib and Seaborn.

## Interactive Dashboard

We created an interactive dashboard using **Streamlit** to allow business users to explore the RFM data dynamically.

### Features:
- ğŸ›ï¸ Filter by RFM segment
- ğŸ‘¤ View detailed customer scores
- ğŸ“Š Visual summary charts (e.g. RFM score counts)
- ğŸ“¥ Download segmented data (coming soon)

### Launch the dashboard locally:
```bash
streamlit run dashboards/app.py
```
Note: Requires data/rfm_segments.csv to be already generated by the notebook 02_rfm.ipynb

## Usage

Follow these steps to run the project end-to-end:

1. ğŸ§¼ Run `notebooks/01_cleaning.ipynb`  
   â†’ Cleans the raw dataset and exports `cleaned_retail.csv`.

2. ğŸ“Š Run `notebooks/02_rfm.ipynb`  
   â†’ Calculates RFM metrics, scores, and segments. Saves `rfm_segments.csv`.

3. ğŸ“ˆ Run `notebooks/04_visualizations.ipynb`  
   â†’ Generates key static charts to support business decisions.

4. ğŸ’» Launch the Streamlit app  
   â†’ Open `dashboards/app.py` to explore results interactively:

```bash
streamlit run dashboards/app.py
```

## Requirements

Install the required Python packages using:

```bash
pip install -r requirements.txt
```

### Core Libraries Used

```text
    pandas
    numpy
    matplotlib
    seaborn
    streamlit
    openpyxl
```

## Contributing

Contributions are welcome! To suggest improvements or submit fixes:

1. Fork this repository  
2. Create a new branch:  
   ```bash
    git checkout -b feature-name
    git commit -m "Add new feature"
    git push origin feature-name
    ```
## License & Contact

- **License**: MIT  
- **Author**: Joseph 
- **Contact**: uyanajoseph@gmail.com
- **Portfolio**: [My Portfolio](https://www.datascienceportfol.io/uyanajoseph)



